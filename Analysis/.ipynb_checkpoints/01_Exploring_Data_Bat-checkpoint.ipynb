{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Data - 01/24/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is pulled from: https://dryad.figshare.com/articles/dataset/Sequence_Raw_Data_-_Part_1/10649372\n",
    "\n",
    "Sadly there is virtually no information they included when they uploaded the data and the overall paper didn't illucidate much in terms of whats going into these files - but these should be the raw Illumina reads from *Tadarida teniotis*, the European free-tailed bat, dietary samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decompressing and Choosing Files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off we need to unzip this rar file... requires isntalling rar from homebrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UNRAR 6.00 freeware      Copyright (c) 1993-2020 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from bat_metabarcoding_diet/RawData_Mata_etal.part1.rar\n",
      "\n",
      "Extracting  86_S86_L001_R2_001.fastq.gz                                      2  OK \n",
      "Extracting  87_S87_L001_R1_001.fastq.gz                                    3  OK \n",
      "Extracting  87_S87_L001_R2_001.fastq.gz                                      5  OK \n",
      "Extracting  88_S88_L001_R1_001.fastq.gz                                      7  OK \n",
      "Extracting  88_S88_L001_R2_001.fastq.gz                                      9  OK \n",
      "Extracting  89_S89_L001_R1_001.fastq.gz                                   1 11  OK \n",
      "Extracting  89_S89_L001_R2_001.fastq.gz                                 1 1 13  OK \n",
      "Extracting  90_S90_L001_R1_001.fastq.gz                                 1 1 15  OK \n",
      "Extracting  90_S90_L001_R2_001.fastq.gz                                 1 1 17  OK \n",
      "Extracting  91_S91_L001_R1_001.fastq.gz                                 1 1 19  OK \n",
      "Extracting  91_S91_L001_R2_001.fastq.gz                                 1 2 21  OK \n",
      "Extracting  1_S1_L001_R1_001.fastq.gz                                   2 2 23  OK \n",
      "Extracting  1_S1_L001_R2_001.fastq.gz                                   2 24  OK \n",
      "Extracting  2_S2_L001_R1_001.fastq.gz                                   2 2 26  OK \n",
      "Extracting  2_S2_L001_R2_001.fastq.gz                                   2 27  OK \n",
      "Extracting  3_S3_L001_R1_001.fastq.gz                                   2 29  OK \n",
      "Extracting  3_S3_L001_R2_001.fastq.gz                                   2 3 31  OK \n",
      "Extracting  4_S4_L001_R1_001.fastq.gz                                   3 32  OK \n",
      "Extracting  4_S4_L001_R2_001.fastq.gz                                   3 3 34  OK \n",
      "Extracting  5_S5_L001_R1_001.fastq.gz                                   3 35  OK \n",
      "Extracting  5_S5_L001_R2_001.fastq.gz                                   3 37  OK \n",
      "Extracting  6_S6_L001_R1_001.fastq.gz                                   3 3 39  OK \n",
      "Extracting  6_S6_L001_R2_001.fastq.gz                                   3 4 41  OK \n",
      "Extracting  7_S7_L001_R1_001.fastq.gz                                   4 42  OK \n",
      "Extracting  7_S7_L001_R2_001.fastq.gz                                   4 44  OK \n",
      "Extracting  8_S8_L001_R1_001.fastq.gz                                   4 4 46  OK \n",
      "Extracting  8_S8_L001_R2_001.fastq.gz                                   4 4 48  OK \n",
      "Extracting  9_S9_L001_R1_001.fastq.gz                                   4 49  OK \n",
      "Extracting  9_S9_L001_R2_001.fastq.gz                                   5 51  OK \n",
      "Extracting  10_S10_L001_R1_001.fastq.gz                                 52  OK \n",
      "Extracting  10_S10_L001_R2_001.fastq.gz                                 53  OK \n",
      "Extracting  11_S11_L001_R1_001.fastq.gz                                 54  OK \n",
      "Extracting  11_S11_L001_R2_001.fastq.gz                                 5 55  OK \n",
      "Extracting  12_S12_L001_R1_001.fastq.gz                                 55  OK \n",
      "Extracting  12_S12_L001_R2_001.fastq.gz                                 56  OK \n",
      "Extracting  13_S13_L001_R1_001.fastq.gz                                 5 5 58  OK \n",
      "Extracting  13_S13_L001_R2_001.fastq.gz                                 5 59  OK \n",
      "Extracting  14_S14_L001_R1_001.fastq.gz                                 6 61  OK \n",
      "Extracting  14_S14_L001_R2_001.fastq.gz                                 6 6 63  OK \n",
      "Extracting  15_S15_L001_R1_001.fastq.gz                                 6 6 65  OK \n",
      "Extracting  15_S15_L001_R2_001.fastq.gz                                 6 6 67  OK \n",
      "Extracting  16_S16_L001_R1_001.fastq.gz                                 6 68  OK \n",
      "Extracting  16_S16_L001_R2_001.fastq.gz                                 6 6 70  OK \n",
      "Extracting  17_S17_L001_R1_001.fastq.gz                                 7 7 72  OK \n",
      "Extracting  17_S17_L001_R2_001.fastq.gz                                 7 7 74  OK \n",
      "Extracting  18_S18_L001_R1_001.fastq.gz                                 7 7 76  OK \n",
      "Extracting  18_S18_L001_R2_001.fastq.gz                                 7 7 78  OK \n",
      "Extracting  19_S19_L001_R1_001.fastq.gz                                 7 79  OK \n",
      "Extracting  19_S19_L001_R2_001.fastq.gz                                 8 81  OK \n",
      "Extracting  20_S20_L001_R1_001.fastq.gz                                 8 83  OK \n",
      "Extracting  20_S20_L001_R2_001.fastq.gz                                 8 8 85  OK \n",
      "Extracting  21_S21_L001_R1_001.fastq.gz                                 8 86  OK \n",
      "Extracting  21_S21_L001_R2_001.fastq.gz                                 8 88  OK \n",
      "Extracting  22_S22_L001_R1_001.fastq.gz                                 89  OK \n",
      "Extracting  22_S22_L001_R2_001.fastq.gz                                 8 90  OK \n",
      "Extracting  23_S23_L001_R1_001.fastq.gz                                 9 91  OK \n",
      "Extracting  23_S23_L001_R2_001.fastq.gz                                 9 92  OK \n",
      "Extracting  24_S24_L001_R1_001.fastq.gz                                 92  OK \n",
      "Extracting  24_S24_L001_R2_001.fastq.gz                                 93  OK \n",
      "Extracting  25_S25_L001_R1_001.fastq.gz                                 9 9 95  OK \n",
      "Extracting  25_S25_L001_R2_001.fastq.gz                                 9 9 97  OK \n",
      "Extracting  26_S26_L001_R1_001.fastq.gz                                 9 9 99  OK \n",
      "Extracting  26_S26_L001_R2_001.fastq.gz                                 99%\n",
      "Cannot find volume bat_metabarcoding_diet/RawData_Mata_etal.part2.rar\n",
      "26_S26_L001_R2_001.fastq.gz - checksum error\n",
      "Total errors: 1\n"
     ]
    }
   ],
   "source": [
    "! unrar x bat_metabarcoding_diet/RawData_Mata_etal.part1.rar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have that decompressed we can see it is a file full of more compressed .gz files. Let's just select a subset of files to use as a base line. I'm going to separate 1 and 2 into it's own file and work this just those files for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gunzip -k ../../Bat_Data/1_S1_L001_R1_001.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gunzip -k ../../Bat_Data/1_S1_L001_R2_001.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! gunzip -k Bat_Data/2_S2_L001_R1_001.fastq.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! gunzip -k ../../Bat_Data/2_S2_L001_R2_001.fastq.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We should come back to this and figure out a way to decompress all those files at once... maybe use the list function and maybe pass a list of the files through the gunzip function?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I'm just going to be working with the first file so I can see what's up with it and if there is anything super interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@M01998:2:000000000-A5JRV:1:1101:14207:1817 1:N:0:1\n",
      "TGCAGATATTGGAACTTTATATTTTATTTTTGGGATTTGAGCTGGAATAGTAGGAACTTCATTAAGATTATTAATTCGAGCTGAATTAGGAAATCCAGGATCTTTAATTGGTGATGATCAAATTTATAATACAATTGTTACAGCACATGCTTTTATTATAATTTTTTTTATAGTTATACCTATTATAATCGGAGGATTTGGTAATTGATTAGTAAC\n",
      "+\n",
      "AAAA?1D1FFFBFGGFGGFGGGHHGBHHHHHGCEFHHHFGGHHFFGHHHHHGHF1GCGHHGHHHHGHHHHHHGHHHHFHHEFHHGHHGHHEHHHHHGHHGHHHHHHFHHHHHGHHHEHHHHEGHHHHHHHHFGGHHDGHHHFHHHHHHHGHHHHHHHHHGFGHHHHGGGHHGHHGGHGHHHHHHHHHHHFFG?CGCHHHHHHHFHHHFHHFFFFFH\n",
      "@M01998:2:000000000-A5JRV:1:1101:15563:1842 1:N:0:1\n",
      "TGCAGATATTGGAACATTATATTTTATTTTTGGAGCTTGGGCCGGTATAGTAGGAACTTCTTTAAGAATTTTAATTCGAGCAGAACTTGGTCATCCTGGGGCATTAATTGGGGATGACCAAATTTATAATGTTATTGTAACAGCTCATGCATTTATTATAATTTTTTTTATAGTTATACCTATTATAATTGGAGGATTTGGTAATTGATTAGTTGCA\n",
      "+\n",
      "AAAAA111DFFBGGGAGGFGFGHHGHHHHHHGEFG0GHFGCFGGG/AFHHGGHHBB0FHFHHHHHGF1BFGHHFHHHFFCAGFHGBHHHHHHHHHHHHHECAEFFHFHHHHHGGGG1FGHHEGHH>FHGHHHHHHHFHHHHHHHHHHHEEFHHFHHHHHH2FFHHHGGGGHGFHGGGDHBHGGFDGF<GHHHEFGCHFHHHGH0DGHBHFGFHH0GB\n",
      "@M01998:2:000000000-A5JRV:1:1101:16557:1847 1:N:0:1\n",
      "GTAGATATTGGAACATTATATTTTATTTTTGGGATTTGAGCTGGAATAGTAGGAACTTCATTAAGATTATTAATTCGAGCTGAATTAGGAAATCCAGGATCTTTAATTGGTGATGATCAAATTTATAATACAATTGTTACAGCACATGCTTTTATTATAATTTTTTTTATAGTTATACCTATTATAATCGGAGGATTTGGTAATTGATTAGTAAC\n"
     ]
    }
   ],
   "source": [
    "! head ../../Bat_Data/1_S1_L001_R1_001.fastq #see the first few entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I very quickly copied the first sequence and manually plugged it into NCBI blast and its an *Agrotis* genus moth species! The second is some type of *Tipula* genus (mosquito eater) insect! This is cool actually kinda impressed by this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A breakdown of how to read fastq files (in order):\n",
    "##### First Line\n",
    "*@instrument:run number:flowcell ID:lane:tile:x-pos:y-pos read:is filtered:control number:index* \n",
    "    \n",
    "- @ starts each sequence identifier line\n",
    "- Instrument ID\n",
    "- Run number on instrument\n",
    "- Flowcell ID\n",
    "- Lane number\n",
    "- Tile number\n",
    "- X coordinate of clsuter\n",
    "- Y coordinate of lcuster\n",
    "- Read number 1 can be single read or Read 2 of paired-end\n",
    "- Y if the read is filtered, N otherwise\n",
    "- 0 when none of the control bits are on, otherwise an even number\n",
    "- Sample number\n",
    "\n",
    "##### Second Line\n",
    "\n",
    "The nucleotide sequence of a single read (DNA fragment)\n",
    "\n",
    "##### Third Line\n",
    "Contains a quality score identifier and is always a \"+\" sign\n",
    "\n",
    "##### Fourth Line\n",
    "\n",
    "Contains basecall quality score for each nucleotide in the sequence shown in line two. These are Phred +33 econded scores using ASCII characters to represent the numerical quality scores\n",
    "\n",
    "The number of records in a fastq file equals the number of reads generated during a sequencing run. On an Illumina MiniSeq isntruement there can be up to 100M records in a single file. \n",
    "\n",
    "If you have paired end reads you will have files that are xxx_R1.fastq and xxx_R2.fastq. R1 contains foward reads, R2 contains reverse reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primers used: ZBJ-ArtF1c and ZBJ-ArtR2c \n",
    "\n",
    "Here is some information on those primers:https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1755-0998.2010.02920\n",
    "\n",
    "\n",
    "ZBJ-ArtF1c: AGATATTGGAACWTTATATTTTATTTTTGG\n",
    "\n",
    "ZBJ-ArtR2c: WACTAATCAATTWCCAAATCCTCC\n",
    "\n",
    "*W = A or T*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  260536  325670 31726819 Bat_Data/1_S1_L001_R1_001.fastq\n",
      "wc: 1_S1_L001_R2_001.fastq: open: No such file or directory\n",
      "  260536  325670 31726819 total\n"
     ]
    }
   ],
   "source": [
    "!wc ../../Bat_Data/1_S1_L001_R1_001.fastq 1_S1_L001_R2_001.fastq #why does the second file not work???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line count divided by 4 should be our actual value of entries! I tried the bioawk command and it wasn't found so not sure what's up with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 tracykreling  staff    30M Feb 23  2016 Bat_Data/1_S1_L001_R1_001.fastq\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ../../Bat_Data/1_S1_L001_R1_001.fastq #check to see how large file is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastQC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following Youtube video to get this to work! The chmod is the difference I think. Prior to that it was permission denying me on everything so yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /Applications/FastQC/fastqc: Permission denied\n"
     ]
    }
   ],
   "source": [
    "! /Applications/FastQC/fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "! chmod u+x /Applications/FastQC/fastqc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            FastQC - A high throughput sequence QC analysis tool\n",
      "\n",
      "SYNOPSIS\n",
      "\n",
      "\tfastqc seqfile1 seqfile2 .. seqfileN\n",
      "\n",
      "    fastqc [-o output dir] [--(no)extract] [-f fastq|bam|sam] \n",
      "           [-c contaminant file] seqfile1 .. seqfileN\n",
      "\n",
      "DESCRIPTION\n",
      "\n",
      "    FastQC reads a set of sequence files and produces from each one a quality\n",
      "    control report consisting of a number of different modules, each one of \n",
      "    which will help to identify a different potential type of problem in your\n",
      "    data.\n",
      "    \n",
      "    If no files to process are specified on the command line then the program\n",
      "    will start as an interactive graphical application.  If files are provided\n",
      "    on the command line then the program will run with no user interaction\n",
      "    required.  In this mode it is suitable for inclusion into a standardised\n",
      "    analysis pipeline.\n",
      "    \n",
      "    The options for the program as as follows:\n",
      "    \n",
      "    -h --help       Print this help file and exit\n",
      "    \n",
      "    -v --version    Print the version of the program and exit\n",
      "    \n",
      "    -o --outdir     Create all output files in the specified output directory.\n",
      "                    Please note that this directory must exist as the program\n",
      "                    will not create it.  If this option is not set then the \n",
      "                    output file for each sequence file is created in the same\n",
      "                    directory as the sequence file which was processed.\n",
      "                    \n",
      "    --casava        Files come from raw casava output. Files in the same sample\n",
      "                    group (differing only by the group number) will be analysed\n",
      "                    as a set rather than individually. Sequences with the filter\n",
      "                    flag set in the header will be excluded from the analysis.\n",
      "                    Files must have the same names given to them by casava\n",
      "                    (including being gzipped and ending with .gz) otherwise they\n",
      "                    won't be grouped together correctly.\n",
      "                    \n",
      "    --nano          Files come from nanopore sequences and are in fast5 format. In\n",
      "                    this mode you can pass in directories to process and the program\n",
      "                    will take in all fast5 files within those directories and produce\n",
      "                    a single output file from the sequences found in all files.                    \n",
      "                    \n",
      "    --nofilter      If running with --casava then don't remove read flagged by\n",
      "                    casava as poor quality when performing the QC analysis.\n",
      "                   \n",
      "    --extract       If set then the zipped output file will be uncompressed in\n",
      "                    the same directory after it has been created.  By default\n",
      "                    this option will be set if fastqc is run in non-interactive\n",
      "                    mode.\n",
      "                    \n",
      "    -j --java       Provides the full path to the java binary you want to use to\n",
      "                    launch fastqc. If not supplied then java is assumed to be in\n",
      "                    your path.\n",
      "                   \n",
      "    --noextract     Do not uncompress the output file after creating it.  You\n",
      "                    should set this option if you do not wish to uncompress\n",
      "                    the output when running in non-interactive mode.\n",
      "                    \n",
      "    --nogroup       Disable grouping of bases for reads >50bp. All reports will\n",
      "                    show data for every base in the read.  WARNING: Using this\n",
      "                    option will cause fastqc to crash and burn if you use it on\n",
      "                    really long reads, and your plots may end up a ridiculous size.\n",
      "                    You have been warned!\n",
      "                    \n",
      "    --min_length    Sets an artificial lower limit on the length of the sequence\n",
      "                    to be shown in the report.  As long as you set this to a value\n",
      "                    greater or equal to your longest read length then this will be\n",
      "                    the sequence length used to create your read groups.  This can\n",
      "                    be useful for making directly comaparable statistics from \n",
      "                    datasets with somewhat variable read lengths.\n",
      "                    \n",
      "    -f --format     Bypasses the normal sequence file format detection and\n",
      "                    forces the program to use the specified format.  Valid\n",
      "                    formats are bam,sam,bam_mapped,sam_mapped and fastq\n",
      "                    \n",
      "    -t --threads    Specifies the number of files which can be processed\n",
      "                    simultaneously.  Each thread will be allocated 250MB of\n",
      "                    memory so you shouldn't run more threads than your\n",
      "                    available memory will cope with, and not more than\n",
      "                    6 threads on a 32 bit machine\n",
      "                  \n",
      "    -c              Specifies a non-default file which contains the list of\n",
      "    --contaminants  contaminants to screen overrepresented sequences against.\n",
      "                    The file must contain sets of named contaminants in the\n",
      "                    form name[tab]sequence.  Lines prefixed with a hash will\n",
      "                    be ignored.\n",
      "\n",
      "    -a              Specifies a non-default file which contains the list of\n",
      "    --adapters      adapter sequences which will be explicity searched against\n",
      "                    the library. The file must contain sets of named adapters\n",
      "                    in the form name[tab]sequence.  Lines prefixed with a hash\n",
      "                    will be ignored.\n",
      "                    \n",
      "    -l              Specifies a non-default file which contains a set of criteria\n",
      "    --limits        which will be used to determine the warn/error limits for the\n",
      "                    various modules.  This file can also be used to selectively \n",
      "                    remove some modules from the output all together.  The format\n",
      "                    needs to mirror the default limits.txt file found in the\n",
      "                    Configuration folder.\n",
      "                    \n",
      "   -k --kmers       Specifies the length of Kmer to look for in the Kmer content\n",
      "                    module. Specified Kmer length must be between 2 and 10. Default\n",
      "                    length is 7 if not specified.\n",
      "                    \n",
      "   -q --quiet       Supress all progress messages on stdout and only report errors.\n",
      "   \n",
      "   -d --dir         Selects a directory to be used for temporary files written when\n",
      "                    generating report images. Defaults to system temp directory if\n",
      "                    not specified.\n",
      "                    \n",
      "BUGS\n",
      "\n",
      "    Any bugs in fastqc should be reported either to simon.andrews@babraham.ac.uk\n",
      "    or in www.bioinformatics.babraham.ac.uk/bugzilla/\n",
      "                   \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "! /Applications/FastQC/fastqc -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of 1_S1_L001_R1_001.fastq\n",
      "Approx 5% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 10% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 15% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 20% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 25% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 30% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 35% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 40% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 45% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 50% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 55% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 60% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 65% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 70% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 75% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 80% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 85% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 90% complete for 1_S1_L001_R1_001.fastq\n",
      "Approx 95% complete for 1_S1_L001_R1_001.fastq\n",
      "Analysis complete for 1_S1_L001_R1_001.fastq\n"
     ]
    }
   ],
   "source": [
    "!/Applications/FastQC/fastqc \\\n",
    "../../Bat_Data/1_S1_L001_R1_001.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tracykreling/Desktop/School/FISH546_Git/Sam-Metabarcoding/Analysis'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting quality score to PHRED quality score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in order to just learn this, I'm going to just copy and paste the first ASCII score from the first entry of the first file... Need to learn how to isolate just that line.. I assume it has to do something with calling each 4th line maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual = \"AAAA?1D1FFFBFGGFGGFGGGHHGBHHHHHGCEFHHHFGGHHFFGHHHHHGHF1GCGHHGHHHHGHHHHHHGHHHHFHHEFHHGHHGHHEHHHHHGHHGHHHHHHFHHHHHGHHHEHHHHEGHHHHHHHHFGGHHDGHHHFHHHHHHHGHHHHHHHHHGFGHHHHGGGHHGHHGGHGHHHHHHHHHHHFFG?CGCHHHHHHHFHHHFHHFFFFFH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phred = [ord(b) -33 for b in qual] # I htink this is Illumina 1.8+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.000630957344480193,\n",
       " 0.000630957344480193,\n",
       " 0.000630957344480193,\n",
       " 0.000630957344480193,\n",
       " 0.001,\n",
       " 0.025118864315095794,\n",
       " 0.00031622776601683794,\n",
       " 0.025118864315095794,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.0005011872336272725,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.0005011872336272725,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00039810717055349735,\n",
       " 0.00025118864315095795,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.025118864315095794,\n",
       " 0.00015848931924611142,\n",
       " 0.00039810717055349735,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00025118864315095795,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00025118864315095795,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00025118864315095795,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00025118864315095795,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00031622776601683794,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00015848931924611142,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00015848931924611142,\n",
       " 0.001,\n",
       " 0.00039810717055349735,\n",
       " 0.00015848931924611142,\n",
       " 0.00039810717055349735,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674,\n",
       " 0.00012589254117941674,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00019952623149688788,\n",
       " 0.00012589254117941674]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimated probability that each base is correct\n",
    "[10**(-q/10) for q in phred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok I know the text book shows similarly small numbers, but if these are probabilities for each base, that seems kind of low and like the entire thing could just be wrong?\n",
    "\n",
    "Ok even more confused because the next sentence they give is Notice how the bases’ accuracies decline in the previous example; this a characteristic error distribution for Illumina sequencing... and the number increase in size??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's trim these files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's use the sickle method, then the seqtk method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FastQ records kept: 65065\n",
      "FastQ records discarded: 69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! sickle se -f ../../Bat_Data/1_S1_L001_R1_001.fastq -t sanger -o ../../Bat_Data/1_S1_L001_R1_001_sickle.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] unrecognized command '../../Bat_Data/1_S1_L001_R1_001.fastq'. Abort!\n"
     ]
    }
   ],
   "source": [
    "! seqtk ../../Bat_Data/1_S1_L001_R1_001.fastq > ../../Bat_Data/1_S1_L001_R1_001_seqtk.fastq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
